{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "path = os.path.join('datasets', 'NLP_Desaster_Tweets')\n",
    "train_path = os.path.join(path, 'tweets_desaster_train.csv')\n",
    "test_path = os.path.join(path, 'tweets_desaster_test.csv')\n",
    "sample_path = os.path.join(path, 'sample_submission.csv')\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "\n",
    "train_data[train_data['target']==1]['text'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda x: remove_url(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html = re.compile(r'<.*?>')\n",
    "    return html.sub(r'', text)\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda x: remove_html(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda x: remove_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    table= str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker  # depending on your System this will take some while\n",
    "\n",
    "spell = SpellChecker()\n",
    "def correct_spelling(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return ''.join(corrected_text)\n",
    "\n",
    "\n",
    "train_data['text']=train_data['text'].apply(lambda x : correct_spelling(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 53)\n",
      "[[0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0\n",
      "  0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "\n",
    "example_train_vector = count_vectorizer.fit_transform(train_data['text'][0:5])\n",
    "\n",
    "print(example_train_vector[0].todense().shape)\n",
    "print(example_train_vector[0].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_data['text'])\n",
    "test_vectors = count_vectorizer.transform(test_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "ridge_clf = RidgeClassifier()\n",
    "forest_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
       "                             ('rf', RandomForestClassifier()), ('svc', SVC()),\n",
       "                             ('ridge', RidgeClassifier())])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', forest_clf), ('svc', svm_clf), ('ridge', ridge_clf)], voting='hard')\n",
    "\n",
    "voting_clf.fit(train_vectors, train_data['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier [0.53035144 0.50089445 0.59010802]\n",
      "SVC [0.59710495 0.55477855 0.64382817]\n",
      "RidgeClassifier [0.61409043 0.55186104 0.61568627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\NilsK\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier [0.5731782  0.52941176 0.61452514]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for clf in (log_clf, forest_clf, svm_clf, ridge_clf, voting_clf):\n",
    "    clf.fit(train_vectors, train_data['target'])\n",
    "    scores = cross_val_score(clf, train_vectors, train_data['target'], cv=3, scoring='f1')\n",
    "    print(clf.__class__.__name__, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(sample_path)\n",
    "\n",
    "sample_submission['target'] = voting_clf.predict(test_vectors)\n",
    "\n",
    "sample_submission.to_csv('submission_v3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2944177e169ee8a5e44b2f456a8eb8401d9c14b3fb068016674666f8895d93"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
